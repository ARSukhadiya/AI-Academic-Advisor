{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For training a model, we are using data (a public dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student-mat.csv\"\n",
    "df = pd.read_csv(url, sep=';')  # UCI's dataset uses ';' as separator\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Example for collecting custom data: User input simulation (grades, course preferences)\n",
    "# # This could be replaced with actual input collection from a web form or API\n",
    "# def collect_custom_data():\n",
    "#     data = {\n",
    "#         \"education\": \"BS in Computer Science\",\n",
    "#         \"skills\": [\"Python\", \"JavaScript\", \"TypeScript\", \"Java\"],\n",
    "#         \"interests\": [\"Machine Learning\", \"Blockchain\", \"Dart\", \"Algorithms\"],\n",
    "#         \"timeline\": 2  # expected/targeted years of education\n",
    "#     }\n",
    "#     return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# # Collect custom data\n",
    "# custom_data = collect_custom_data()\n",
    "\n",
    "\n",
    "# # Merge custom data with public data (if needed)\n",
    "# df = pd.concat([df, custom_data], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "\n",
    "# Handle missing values (e.g., fill missing with the mean or drop rows/columns)\n",
    "# Here we fill missing values with the mean (for numeric columns)\n",
    "df.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performed data-preprocessing (with StandardScaler and MinMaxScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Standardize numerical columns (mean=0, std=1)\n",
    "scaler = StandardScaler()\n",
    "df[['grade_math', 'grade_portuguese', 'study_time']] = scaler.fit_transform(df[['grade_math', 'grade_portuguese', 'study_time']])\n",
    "\n",
    "\n",
    "# Alternatively, you could normalize them (min=0, max=1)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "df[['grade_math', 'grade_portuguese']] = min_max_scaler.fit_transform(df[['grade_math', 'grade_portuguese']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding (LabelEncoder and One Hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encoding categorical data: 'course_interests'\n",
    "le = LabelEncoder()\n",
    "df['course_interests_encoded'] = le.fit_transform(df['course_interests'])\n",
    "\n",
    "# One-hot encoding example for categorical features with more than two categories\n",
    "df = pd.get_dummies(df, columns=['course_interests'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming we have grades for different subjects, we can calculate the GPA\n",
    "df['GPA'] = df[['grade_math', 'grade_portuguese']].mean(axis=1)\n",
    "\n",
    "# Feature: Total Study Time (Sum of study time in different courses)\n",
    "df['total_study_time'] = df['study_time'] * 2  # Just as an example, you can make it more complex\n",
    "\n",
    "# Another example: Creating a new feature from 'extra_activities'\n",
    "df['is_active_student'] = np.where(df['extra_activities'] == 1, 'Yes', 'No')\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# coninued..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_performance, test_size=0.3, random_state=42)\n",
    "X_train_career, X_test_career, y_train_career, y_test_career = train_test_split(X_career, y_career, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize/Scale data (important for many ML models like Logistic Regression)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Performance Prediction (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Performance Prediction (Regression)\n",
    "\n",
    "# Model 1: Random Forest Regressor for GPA prediction\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict performance (GPA)\n",
    "y_pred_performance = rf_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model using Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred_performance)\n",
    "print(f\"Performance Prediction (MSE): {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Career Path Prediction (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Career Path Prediction (Classification)\n",
    "\n",
    "# Model 2: Random Forest Classifier for Career Path Prediction\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_scaled, y_train_career)\n",
    "\n",
    "# Predict career path\n",
    "y_pred_career = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model using Accuracy\n",
    "accuracy = accuracy_score(y_test_career, y_pred_career)\n",
    "print(f\"Career Path Prediction (Accuracy): {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use XGBoost (as an alternative to Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Use XGBoost (as an alternative to Random Forest)\n",
    "# Model 3: XGBoost Classifier for Career Path Prediction\n",
    "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
    "xgb_classifier.fit(X_train_scaled, y_train_career)\n",
    "\n",
    "# Predict career path using XGBoost\n",
    "y_pred_career_xgb = xgb_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the XGBoost model\n",
    "accuracy_xgb = accuracy_score(y_test_career, y_pred_career_xgb)\n",
    "print(f\"XGBoost Career Path Prediction (Accuracy): {accuracy_xgb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression Model for Career Path Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Logistic Regression Model for Career Path Prediction\n",
    "# Model 4: Logistic Regression for Career Path Prediction\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train_scaled, y_train_career)\n",
    "\n",
    "# Predict career path\n",
    "y_pred_career_logreg = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate Logistic Regression model\n",
    "accuracy_logreg = accuracy_score(y_test_career, y_pred_career_logreg)\n",
    "print(f\"Logistic Regression Career Path Prediction (Accuracy): {accuracy_logreg}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
